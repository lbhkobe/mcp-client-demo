server:
  port: 8080

spring:
  application:
    name: mcp-server
  ai:
    ollama: # 引入ollama配置
      base-url: http://localhost:11434
      init:
        pull-model-strategy: never # 是否在启动时拉取模型以及如何拉取。
        timeout: 60s # 拉取模型超时时间。
      chat:
        model: qwen2.5:0.5b #deepseek-r1:latest #要使用的支持的模型的名称。
    model: # ai模型选择
      chat: ollama # 启用Ollama聊天模型。
    mcp: # 启用MCP
      client:  # MCP CLIENT配置
        #stdio:
          # servers-configuration: classpath:/mcp-servers.json
        type: async
        request-timeout: 60s
        sse:
          connections:
              server1:
                url: https://mcp.amap.com
                sse-endpoint: /sse?key=2549fa069752fb0ec89ed9e409690044


logging:
  level:
    com.example.mcpserver: INFO
    org.springframework.ai: INFO