server:
  port: 8080

spring:
  application:
    name: mcp-client
  ai:
#    ollama: # 引入ollama配置
#      base-url: http://localhost:11434
#      init:
#        pull-model-strategy: never # 是否在启动时拉取模型以及如何拉取。
#        timeout: 10s # 拉取模型超时时间。
#      chat:
#        model: qwen2.5:0.5b #deepseek-r1:latest #要使用的支持的模型的名称。
    model: # ai模型选择
      chat: openai # 启用Ollama聊天模型。
    openai:
      api-key: ${OPENAI_API_KEY:vfiBiNt3JyUZBouSyOKterhIbq084kfu} # OpenAI API密钥，可通过环境变量设置
      model: deepseek-v3-jhk # 使用的OpenAI模型
      base-url: https://inner-apisix.hisense.com/compatible-openai # OpenAI API基础URL
      connect-timeout: 30s # 连接超时时间
      read-timeout: 60s # 读取超时时间
      chat:
        options:
            model: deepseek-v3-jhk
            temperature: 0.7
        completions-path: /v1/chat/completions?user_key=baccow4ba0wijfelehu1gwlcq82mvzl7
    mcp: # 启用MCP
      client:  # MCP CLIENT配置
        type: async
        request-timeout: 10s
#        stdio:
#         servers-configuration: classpath:/mcp-servers-config.json
        sse:
          connections:
            server1:
                url: https://mcp.amap.com
                sse-endpoint: /sse?key=77cdac6f31f39b6476c552b87484fce8
            msc-product-mcp-server:
                url: http://localhost:8082
               # sse-endpoint: /mcp/messages
#            server3:
#               url: https://mcp-09724909-442f-4b85.api-inference.modelscope.cn


logging:
  level:
    com.example.mcpserver: INFO
    org.springframework.ai: INFO
    com.example.mcp.service: DEBUG # 添加OpenAIService的日志级别